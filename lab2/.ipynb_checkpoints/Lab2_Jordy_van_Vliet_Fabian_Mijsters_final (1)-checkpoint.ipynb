{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cdf5c1e89cd73689",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lab 2: Sequence Models\n",
    "\n",
    "In this lab, you will implement a **Hidden Markov Model (HMM)**. HMMs specify a **joint** probability over **observations** and **hidden states**. \n",
    "\n",
    "This is what we will do today:\n",
    "\n",
    "1. **Estimate** a simple HMM model from training data (supervised learning)\n",
    "2. Find the *best* sequence of hidden states for a given sequence of observations (we define \"best\" in 2 different ways!)\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "### Rules\n",
    "* The lab exercises should be made in **groups of two people**.\n",
    "\n",
    "* The assignment should submitted to **Blackboard** as `.ipynb`. Only **one submission per group**. See Blackboard for date of submission. \n",
    "\n",
    "* The **filename** should be `lab2_id1_id2.ipynb`.\n",
    "\n",
    "* The notebook is graded on a scale of **0-50**. The number of points for each question is indicated in parantheses. (Note: The total of 50 points is only for convenience and will be scaled- each of the four labs has the same weight in the course.) \n",
    "\n",
    "* The questions marked **Extra** are not obligatory; try them if you want an extra challenge. \n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should **write your code and answers in this iPython Notebook** (see http://ipython.org/notebook.html for reference material). If you have problems, please contact your teaching assistant.\n",
    "\n",
    "* Use only **one cell for code** and **one cell for markdown** answers!    \n",
    "\n",
    "    * Put all code in the cell with the `# YOUR CODE HERE` comment.\n",
    "    \n",
    "    * For theoretical question, put your solution in the YOUR ANSWER HERE cell.\n",
    "    \n",
    "* Test your code and **make sure we can run your notebook**\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c20720f24702422e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Notation\n",
    "\n",
    "$ \\Sigma := \\{ o_1, \\dots, o_J \\} $ is our set of **observations**\n",
    "\n",
    "$\\Lambda := \\{c_1, \\dots, c_K \\}$ is our set of **state labels**\n",
    "\n",
    "$\\Sigma^*$ are **all possible sequences** of observations (including empty string $\\epsilon$)\n",
    "\n",
    "$\\Lambda^*$ all possible sequences of hidden states (including empty string $\\epsilon$)\n",
    "\n",
    "> Extra info: we can say that $\\Sigma^*$ is the [Kleene-closure](https://en.wikipedia.org/wiki/Kleene_star) of $\\Sigma$, and $\\Lambda^*$ the Kleene-closure of $\\Lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0563c61a6ff0ee4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## A simple example: The Baby HMM\n",
    "\n",
    "We start with a simple example, so that we can easily verify that our code is correct.\n",
    "\n",
    "Consider that we are modeling how a baby behaves. We observe the baby doing the following things: laughing (`laugh`), crying (`cry`), and sleeping (`sleep`). This is our set $\\Sigma$ of **observations**. \n",
    "\n",
    "We presume that, at any moment, the baby can be either `hungry`, `bored`, or `happy`. Since babies cannot talk, each of these states is hidden. This is our set $\\Lambda$ of **hidden states**.\n",
    "\n",
    "**Now the question is: if we have a series of observations, can we predict what hidden states the baby went through?**\n",
    "\n",
    "To tackle this problem, we assume that the baby behaves like a **1st order discrete Markov chain**: the baby's current state only depends on its previous hidden state. The baby can be described as an HMM. (Yay!)\n",
    "\n",
    "For example, assume we observed the baby doing the following:\n",
    "\n",
    "```\n",
    "sleep cry laugh cry\n",
    "cry cry laugh sleep\n",
    "```\n",
    "\n",
    "We will use these sequences as our **test set**. We can try to find out the states of the baby for those observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2fe112701eae5d42",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, to train our model, we will need some examples of **observations** and **states**; this is our **training set**:\n",
    "\n",
    "```\n",
    "laugh/happy cry/bored cry/hungry sleep/happy\n",
    "cry/bored laugh/happy cry/happy sleep/happy\n",
    "cry/hungry laugh/happy cry/bored sleep/happy\n",
    "```\n",
    "\n",
    "So we have **pairs** observation/state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a80c3b9c59cfc01",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab15ee4ee723c00e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set (observations):\n",
      "['sleep', 'cry', 'laugh', 'cry']\n",
      "['cry', 'cry', 'laugh', 'sleep']\n",
      "\n",
      "training set (observation/state pairs):\n",
      "[laugh/happy, cry/bored, cry/hungry, sleep/happy]\n",
      "[cry/bored, laugh/happy, cry/happy, sleep/bored]\n",
      "[cry/hungry, cry/bored, sleep/happy]\n"
     ]
    }
   ],
   "source": [
    "# read in test data\n",
    "test_data = \"\"\"sleep cry laugh cry\n",
    "cry cry laugh sleep\"\"\"\n",
    "\n",
    "def test_reader(test_lines):\n",
    "    for line in test_lines.splitlines():\n",
    "        yield line.split()\n",
    "\n",
    "test_set = list(test_reader(test_data))\n",
    "\n",
    "# read in train data\n",
    "train_data = \"\"\"laugh/happy cry/bored cry/hungry sleep/happy\n",
    "cry/bored laugh/happy cry/happy sleep/bored\n",
    "cry/hungry cry/bored sleep/happy\"\"\"\n",
    "\n",
    "# for convenience, we define a Observation-State pair class\n",
    "Pair = namedtuple(\"Pair\", [\"obs\", \"state\"])\n",
    "Pair.__repr__ = lambda x: x.obs + \"/\" + x.state\n",
    "\n",
    "def train_reader(train_lines):\n",
    "    for line in train_data.splitlines():\n",
    "        # a pair is a string \"observation/state\" so we need to split on the \"/\"\n",
    "        yield [Pair(*pair.split(\"/\")) for pair in line.split()]\n",
    "\n",
    "training_set = list(train_reader(train_data))\n",
    "\n",
    "# print the results\n",
    "print(\"test set (observations):\")\n",
    "for seq in test_set:\n",
    "    print(seq)\n",
    "print(\"\\ntraining set (observation/state pairs):\")\n",
    "for seq in training_set:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a98845e6e8374535",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Vocabularies \n",
    "It's going to be very useful if we can map states and observations to integers, so that we can identify them by a number. If we don't do this, then our implementation will be much slower. (This is relevant when we work with larger data, e.g. for POS tagging)\n",
    "\n",
    "Make sure you understand what is going on here: every time we look up a observation or state, the `defaultdict` will create a new key (index) if it has not seen that key (state or observation) before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-387cb576fbdc997c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our vocabularies:\n",
      "defaultdict(<function <lambda> at 0x0000010BF66C6F70>, {'happy': 0, 'bored': 1, 'hungry': 2})\n",
      "defaultdict(<function <lambda> at 0x0000010BF66C6D30>, {'laugh': 0, 'cry': 1, 'sleep': 2})\n"
     ]
    }
   ],
   "source": [
    "# create mappings from state/obs to an ID\n",
    "state2i = defaultdict(lambda: len(state2i))\n",
    "obs2i = defaultdict(lambda: len(obs2i))\n",
    "\n",
    "for seq in training_set:\n",
    "    for example in seq:\n",
    "        state_id = state2i[example.state]\n",
    "        obs_id = obs2i[example.obs]\n",
    "        \n",
    "print(\"\\nOur vocabularies:\")\n",
    "print(state2i)\n",
    "print(obs2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2940eafa637320ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The HMM for the first training set sequence looks like this:\n",
    "\n",
    "![hmm-baby-train-1](hmm-baby-train-1.png)\n",
    "\n",
    "Now, we will **estimate** the following probability distributions:\n",
    "\n",
    "- initial: $P( c_k \\,|\\, \\texttt{start})$\n",
    "- transition: $P( c_k \\,|\\, c_l )$\n",
    "- final: $P(\\texttt{stop} \\,|\\, c_k )$\n",
    "- emission: $P( o_l \\,|\\, c_k)$\n",
    "\n",
    "These distributions are all we need. Remember that:\n",
    "\n",
    "- the probability of transitioning to a state $c_k$ only depends on one previous state $c_l$ (1st order Markov assumption).\n",
    "- emitting an observation $o_l$ only depends on the state $c_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-430223fd21b6ce82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Finding the Maximum Likelihood Parameters\n",
    "\n",
    "Now we would like to know what those distributions look like from our data. This is called **estimation**. Given our training data, we count how many times each event occurs and normalize the counts to form proper probability distributions. \n",
    "\n",
    "Let's first do counts for the start probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df74082a4f0715ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# we can get the number of states and observations from our dictionaries\n",
    "num_states = len(state2i)\n",
    "num_observations = len(obs2i)\n",
    "\n",
    "# this creates a vector of length `num_states` filled with zeros\n",
    "counts_start = np.zeros(num_states)\n",
    "\n",
    "# now we count 1 every time a sequence starts with a certain state\n",
    "# we look up the index for the state that we want to count using the `state2i` dictionary\n",
    "for seq in training_set:\n",
    "    counts_start[state2i[seq[0].state]] += 1.\n",
    "\n",
    "print(counts_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba32d826a1471a2a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We see each state once at the beginning of a sequence in the training set, so that is why we have a count of 1 for each of them.\n",
    "\n",
    "We now **normalize** those counts, so that we obtain a probability distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a818b13defb8e711",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start --> [0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "# since p_start is a numpy object, we can call sum on it; easy!\n",
    "total = counts_start.sum()\n",
    "\n",
    "# normalize: divide each count by the total\n",
    "p_start = counts_start / total  \n",
    "print('start', '-->', p_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-efc1949dc9262b12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We now turn to the **transition probabilities** and **stop probabilities**. We count, and then we normalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8f2dba45d15d44c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition counts:\n",
      "[[1. 2. 1.]\n",
      " [2. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "Final counts:\n",
      "[2. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# we can transition from any state to any other state in principle,\n",
    "# so we create a matrix filled with zeros so that we can count any pair of states\n",
    "# in practice, some transitions might not occur in the training data\n",
    "counts_trans = np.zeros([num_states, num_states])\n",
    "\n",
    "# for the final/stop probabilities, we only need to store `num_states` values.\n",
    "# so we use a vector\n",
    "counts_stop = np.zeros(num_states)\n",
    "\n",
    "# now we count transitions, one sequence at a time\n",
    "for seq in training_set:\n",
    "    for i in range(1, len(seq)):\n",
    "        \n",
    "        # convert the states to indexes\n",
    "        prev_state = state2i[seq[i-1].state]\n",
    "        current_state = state2i[seq[i].state]\n",
    "        \n",
    "        # count\n",
    "        counts_trans[current_state, prev_state] += 1.\n",
    "\n",
    "# count final states\n",
    "for seq in training_set:\n",
    "    state = state2i[seq[-1].state]\n",
    "    counts_stop[state] += 1.\n",
    "\n",
    "# print the counts\n",
    "print(\"Transition counts:\")\n",
    "print(counts_trans)\n",
    "\n",
    "print(\"Final counts:\")\n",
    "print(counts_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68e67a73fdfab5d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we can normalize again. We will need to collect the total counts per state.\n",
    "Take some time to understand that the totals consist of the transition counts AND the final counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-262f16a6645038a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Useful trick: np.sum(m, 0) sums matrix m along the first dimension:\n",
    "print(counts_trans.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2720bcd24a328fc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total counts per state:\n",
      " [5. 4. 2.] \n",
      "\n",
      "Transition probabilities:\n",
      " [[0.2  0.5  0.5 ]\n",
      " [0.4  0.   0.5 ]\n",
      " [0.   0.25 0.  ]]\n",
      "Final probabilities:\n",
      " [0.4  0.25 0.  ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_per_state = counts_trans.sum(0) + counts_stop\n",
    "print(\"Total counts per state:\\n\", total_per_state, \"\\n\")\n",
    "\n",
    "# now we normalize\n",
    "# here '/' works one column at a time in the matrix\n",
    "p_trans = counts_trans / total_per_state\n",
    "print(\"Transition probabilities:\\n\", p_trans)\n",
    "\n",
    "# here '/' divides the values in each corresponding index in the 2 vectors\n",
    "p_stop = counts_stop / total_per_state\n",
    "print(\"Final probabilities:\\n\", p_stop, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62194d4b1f2fc0bc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**So far so good!** Now let's take care of **emission probabilities**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission counts:\n",
      " [[2. 0. 0.]\n",
      " [1. 3. 2.]\n",
      " [2. 1. 0.]]\n",
      "p_emiss:\n",
      " [[0.4  0.   0.  ]\n",
      " [0.2  0.75 1.  ]\n",
      " [0.4  0.25 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# now we create a matrix to keep track of emission counts\n",
    "# in principle any states can emit any observation\n",
    "# so we need a matrix again\n",
    "counts_emiss = np.zeros([num_observations, num_states])\n",
    "\n",
    "# count\n",
    "for seq in training_set:\n",
    "    for obs, state in seq:\n",
    "        obs = obs2i[obs]\n",
    "        state = state2i[state]\n",
    "        counts_emiss[obs][state] += 1.\n",
    "\n",
    "# normalize\n",
    "p_emiss = counts_emiss / counts_emiss.sum(0)\n",
    "\n",
    "print(\"emission counts:\\n\", counts_emiss)\n",
    "print(\"p_emiss:\\n\", p_emiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc1d7ccaf0a06283",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This is a good moment for a sanity check. First, take a look at the training set to see if these probabilities are correct, i.e. check if  for each state $s_k$: $$\\sum_l P(s_l \\,|\\, s_k) = 1.0$$ Note that this includes transitions to \"stop\" state, so you have to take those into account.\n",
    "\n",
    "## Exercise 1: Sanity check (2.5 points)\n",
    "Write a function `sanity_check(...)` that checks if all distributions are correct. If (and only if) it discovers an incorrect distribution, it should throw an **AssertionError**. \n",
    "\n",
    "If you want, you can include some print statements to see what is going on. \n",
    "\n",
    "**[Python hint]**: use python [assert](https://www.tutorialspoint.com/python/assertions_in_python.htm) statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def almost_one(p, eps=1e-3):\n",
    "    return (1.-eps) < p < (1. + eps)\n",
    "\n",
    "def sanity_check(p_start=None, p_trans=None, p_stop=None, p_emiss=None):\n",
    "    print('If p_start is true then its values should sum to one and almost_one should return true for this sum:')\n",
    "    print(p_start)\n",
    "    print('almost_one output for p_start is: ')\n",
    "    print(almost_one(p_start.sum(0)))\n",
    "    assert(almost_one(p_start.sum(0)) == True),'The start state probabilities dont add up to 1'\n",
    "    print('''If p_trans and p_stop are true then adding the probability that state x transitions into state y with the probability\n",
    "          that state x is the end state should add up to one. Summation equals: ''')\n",
    "    print(p_stop,'+',p_trans.sum(0),'=', p_trans.sum(0) + p_stop)\n",
    "    assert(len(p_trans.sum(0) + p_stop) == sum(p_trans.sum(0) + p_stop)),'Transition probabilities added with end state probabilities dont add to 1'\n",
    "    print(''' If p_emiss is true then the probability of emitting all the possible observations in a state should add up to one,\n",
    "    which corresponds to summing the elements in each column of p_emiss:''')\n",
    "    print(p_emiss)\n",
    "    print('Summing the columns gives: ')\n",
    "    print(p_emiss.sum(0))\n",
    "    assert(len(p_emiss.sum(0)) == sum(p_emiss.sum(0))),'Emission probabilities do not sum up to 1'\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If p_start is true then its values should sum to one and almost_one should return true for this sum:\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "almost_one output for p_start is: \n",
      "True\n",
      "If p_trans and p_stop are true then adding the probability that state x transitions into state y with the probability\n",
      "          that state x is the end state should add up to one. Summation equals: \n",
      "[0.4  0.25 0.  ] + [0.6  0.75 1.  ] = [1. 1. 1.]\n",
      " If p_emiss is true then the probability of emitting all the possible observations in a state should add up to one,\n",
      "    which corresponds to summing the elements in each column of p_emiss:\n",
      "[[0.4  0.   0.  ]\n",
      " [0.2  0.75 1.  ]\n",
      " [0.4  0.25 0.  ]]\n",
      "Summing the columns gives: \n",
      "[1. 1. 1.]\n",
      "All good!\n"
     ]
    }
   ],
   "source": [
    "# you can try your function out like this\n",
    "# (do not use this cell for your solution)\n",
    "try:\n",
    "    sanity_check(p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
    "    print(\"All good!\")\n",
    "except AssertionError as e:\n",
    "    print(\"There was a problem: %s\" % str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-65c6613cf4767c2f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Decoding a sequence\n",
    "\n",
    "Ok, so we have estimated a model. Great. Now what? Well, now we can **decode**! \n",
    "\n",
    "Given an observation sequence $o_1, o_2, \\dots, o_N$, we want to find the sequence of hidden states $s^* = s^*_1, s^*_2, \\dots, s^*_N$ that **best** explains those observations.\n",
    "\n",
    "But what does \"best\" mean?\n",
    "\n",
    "1. If we are interested in the best **global** assignment of states to the sequence as a whole, we can use the **Viterbi** algorithm. \n",
    "2. If we care more about minimizing the **local** error of getting each $s_i$ right, we can use **posterior decoding** (also called *max marginal decoding*). *(This is a bonus exercise at the end!)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91a84fbaef83d741",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Decoding: The Viterbi Algorithm\n",
    "\n",
    "Viterbi gives us the best global hidden state sequence, i.e.:\n",
    "\n",
    "$$ \\begin{array}{lll}\n",
    "s^* &=& \\arg\\max_{s = s_1, s_2, \\dots, s_N} P(s_1, s_2, \\dots, s_N \\,|\\, o_1, o_2, \\dots, o_N ) \\\\\n",
    "    &=& \\arg\\max_{s = s_1, s_2, \\dots, s_N} P(s_1, s_2, \\dots, s_N, o_1, o_2, \\dots, o_N ) \n",
    "\\end{array}$$\n",
    "\n",
    "To explain Viterbi we will make use of a **trellis**, a kind of graph that shows us the possible states for each time step. \n",
    "\n",
    "For our earlier example, the trellis looks like this:\n",
    "\n",
    "![hmm-baby-train-1](hmm-baby-train-1-trellis.png)\n",
    "\n",
    "Note, that we can now label the edges of this trellis with the following probabilities:\n",
    "\n",
    "- $P_{\\text start}(c_k \\,|\\, \\text{start})$ on the three edges from \"start\"\n",
    "- $P_{\\text stop}(\\text{stop} \\,|\\, c_k)$ on the three edges leading to \"stop\"\n",
    "- $P_{\\text trans}(c_k \\,|\\, c_{l})$ on each remaining edge from state $c_l$ to $c_k$\n",
    "- $P_{\\text emiss}(o \\,|\\, c_k)$ from each state $c_k$, to an observation $o$ made from that state (not shown here)\n",
    "\n",
    "Do you see that our trellis nicely shows the independence assumptions of the HMM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64d5cd7e9c55167a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### A Naive approach to get the best sequence\n",
    "\n",
    "To see why the Viterbi algorithm is so useful, we can consider another way to calculate $s^*$:\n",
    "\n",
    "- Iterate over all possible state sequences (all ways to go from `start` to `stop`)\n",
    "    - Calculate the probability for that sequence\n",
    "    - Store the highest probability seen so far and its sequence\n",
    "- Return the sequence that had the maximum probability\n",
    "\n",
    "The problem with this approach is that there are a lot of possible sequences!\n",
    "\n",
    "# Exercise 2: How many possible state sequences are there? (5 points)\n",
    "\n",
    "*This is a theoretical question.* Assume that you have a set $\\Lambda$ of possible states (so there are $|\\Lambda|$ states), and that the observation sequence is of length $N$. Assume there is a transition from any state to any other state.\n",
    "Write down the formula that gives the number of sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a3f990e075d01747",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "|Λ|^N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58d4f2277d79da32",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### The Viterbi algorithm\n",
    "\n",
    "*We use a slightly different notation here compared to the lecture.*\n",
    "\n",
    "So how do we find the path with the highest score? The idea is that we can use our trellis to represent an **exponential number of paths**. Since we are only interested in the highest-scoring path, for every state at every time step, we only need to keep track of the **highest** probability that can lead us to that state. We can disregard any other paths that lead to that state, since they will for sure not be part of the highest-scoring path.\n",
    "\n",
    "Viterbi uses **dynamic programming**. Here, that means that we will re-use probabilities that we have already computed, so we never have to compute the score for the same sub-problem multiple times.\n",
    "\n",
    "Let's start at the beginning.\n",
    "\n",
    "For the first time step, the **viterbi score** is the transition probability of reaching a state $c_k$ from \"start\", times the probability of emitting the first observation $o_1$ from that state:\n",
    "\n",
    "$$\\text{viterbi}(1, c_k) = P_{\\text start}( c_k \\,|\\, \\text{start}) \\times P_{\\text emiss}(o_1 \\,|\\, c_k)$$\n",
    "\n",
    "So, the Viterbi trellis represents the path with maximum probability in position $i$ when we are in state $y_i$ having observed $o_1, o_2, \\dots, o_i$, the observations up to and including that point.\n",
    "\n",
    "Now that we have the viterbi scores for all states of the first time step in our trellis, we can use the following **recursive formula** to get the scores for all other states, one time step at a time:\n",
    "\n",
    "$$\\text{viterbi}(i, c_k) = \\big( \\max_{c_l \\in \\Lambda} P_{\\text trans}(c_k | c_l) \\times \\text{viterbi}(i-1, c_l) \\big) \\times P_{\\text emiss}(o_i \\,|\\, c_k)$$\n",
    "\n",
    "Finally, for our final state \"stop\" we need to do something special, since there is no observation there:\n",
    "\n",
    "$$\\text{viterbi}(N+1, \\text{stop}) = \\max_{c_l \\in \\Lambda} P_{\\text stop}(\\text{stop} \\,|\\, c_l) \\times \\text{viterbi}(i-1, c_l)  $$\n",
    "\n",
    "This is all we need to know what probability the highest scoring path has! Do you see how the dynamic programming helps us to solve this task efficiently?\n",
    "\n",
    "#### How did we get here?\n",
    "\n",
    "Once we reach the \"stop\" state we know the maximum probability, but we forgot how we got there! If you don't see this immediately, remember that, whenever we computed the viterbi score for a state, we took the maximum over all previous states' viterbi scores, times the transition from those states. But we didn't keep track of which state was actually selected in that \"max\" operation. So now that we are in \"stop\", we don't know how we got there.\n",
    "\n",
    "To solve this, we will use **backpointers**. Whenever we do a $\\max$, we store what state was selected by that max (i.e. the $\\arg\\max$):\n",
    "\n",
    "$$\\text{backtrack}(i, c_k) = \\arg\\max_{c_l \\in \\Lambda} P_{\\text trans}(c_k | c_l) \\times \\text{viterbi}(i-1, c_l)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61fe883db37093ca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Log probabilities\n",
    "\n",
    "Now you know enough to implement Viterbi! But before we start.. Because probabilities tend to get rather small when multiplying, causing numerical instabilities, we will use **log probabilities**. This means that, instead of multiplying, we can now **sum** probabilities, because:\n",
    "\n",
    "$$ \\log(uv) = \\log u + \\log v$$\n",
    "\n",
    "To get the probability of a  path trough our trellis from \"start\" to \"stop\", we can just **sum** the log-probabilities that we encounter. So, finding the best (\"Viterbi\") path means finding the path with the **highest score**.\n",
    "\n",
    "# Exercise 3: convert all probabilities to log-probabilities (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: only run this cell once; otherwise you get NaN values.\n",
    "# If you get NaN values, try running all cells above first.\n",
    "import math\n",
    "def convert_to_log(p_start=None, p_trans=None, p_stop=None, p_emiss=None):\n",
    "    \"\"\"\n",
    "    Convert all probabilities to log-probabilities\n",
    "    \n",
    "    Important: only run this function with normal probabilities as input! \n",
    "    If you run this twice, things will break.\n",
    "    \"\"\"\n",
    "    for i,p in enumerate(p_start):\n",
    "        p_start[i] = math.log(p)\n",
    "    for i,p in enumerate(p_stop):\n",
    "        p_stop[i] = math.log(p)\n",
    "    for ri, row in enumerate(p_trans):\n",
    "        for i,p in enumerate(row):\n",
    "            p_trans[ri][i] = math.log(p)\n",
    "    for ri, row in enumerate(p_emiss):\n",
    "        for i,p in enumerate(row):\n",
    "            p_emiss[ri][i] = math.log(p)\n",
    "        \n",
    "    return p_start, p_trans, p_stop, p_emiss\n",
    "\n",
    "\n",
    "# print(\"Before:\\n\", p_start,\"\\n\", p_trans,\"\\n\", p_stop,\"\\n\", p_emiss)\n",
    "\n",
    "# do the conversion using your function\n",
    "# p_start, p_trans, p_stop, p_emiss = convert_to_log(p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
    "# \n",
    "# print(\"After:\\n\", p_start, p_trans, p_stop, p_emiss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dd2a6b04cf0668e0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Smoothing\n",
    "\n",
    "Oops! We got a big red warning! What happened? \n",
    "\n",
    "Some probabilities were 0.0, and the log function is not defined for zero, resulting in a **warning**.\n",
    "\n",
    "To prevent the error, we can add a small **smoothing** value to our **counts**, so that we never have a probability of zero.\n",
    "\n",
    "To make things easier, we define a `normalize_all` function below that does all the normalization again,\n",
    "but now adding a small value to all the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d511810070a63ddd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed probabilities:\n",
      " [0.33333333 0.33333333 0.33333333] [[0.2037037  0.47727273 0.45833333]\n",
      " [0.38888889 0.02272727 0.45833333]\n",
      " [0.01851852 0.25       0.04166667]] [0.38888889 0.25       0.04166667] [[0.39622642 0.02325581 0.04347826]\n",
      " [0.20754717 0.72093023 0.91304348]\n",
      " [0.39622642 0.25581395 0.04347826]]\n",
      "Smoothed log-probabilities:\n",
      " [-1.09861229 -1.09861229 -1.09861229] [[-1.59108877 -0.7396672  -0.78015856]\n",
      " [-0.94446161 -3.78418963 -0.78015856]\n",
      " [-3.98898405 -1.38629436 -3.17805383]] [-0.94446161 -1.38629436 -3.17805383] [[-0.92576948 -3.76120012 -3.13549422]\n",
      " [-1.57239664 -0.32721291 -0.09097178]\n",
      " [-0.92576948 -1.36330484 -3.13549422]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "def normalize(x, smoothing=0.1, axis=0):\n",
    "    smoothed = x + smoothing\n",
    "    return smoothed / smoothed.sum(axis)\n",
    "\n",
    "def normalize_all(counts_start, counts_trans, counts_stop, counts_emiss, smoothing=0.1):\n",
    "    \"\"\"Normalize all counts to probabilities, optionally with smoothing.\"\"\"\n",
    "    p_start = normalize(counts_start, smoothing=smoothing)\n",
    "    p_emiss = normalize(counts_emiss, smoothing=smoothing)\n",
    "    \n",
    "    counts_trans_smoothed = counts_trans + smoothing\n",
    "    counts_stop_smoothed = counts_stop + smoothing\n",
    "    total_trans_stop = counts_trans_smoothed.sum(0) + counts_stop_smoothed\n",
    "    p_trans = counts_trans_smoothed / total_trans_stop\n",
    "    p_stop = counts_stop_smoothed / total_trans_stop\n",
    "    \n",
    "    return p_start, p_trans, p_stop, p_emiss\n",
    "\n",
    "\n",
    "# normalize with smoothing\n",
    "p_start_n = copy.deepcopy(p_start)\n",
    "p_trans_n = copy.deepcopy(p_trans)\n",
    "p_stop_n = copy.deepcopy(p_stop)\n",
    "p_emiss_n = copy.deepcopy(p_emiss)\n",
    "smoothing = 0.1\n",
    "p_start, p_trans, p_stop, p_emiss = normalize_all(\n",
    "    counts_start, counts_trans, counts_stop, counts_emiss, smoothing=smoothing)\n",
    "\n",
    "# convert to log-probabilities\n",
    "print(\"Smoothed probabilities:\\n\", p_start, p_trans, p_stop, p_emiss)\n",
    "\n",
    "p_start, p_trans, p_stop, p_emiss = convert_to_log(p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
    "print(\"Smoothed log-probabilities:\\n\", p_start, p_trans, p_stop, p_emiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6f521724c6db98b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercise 4: implement the Viterbi algorithm (40 points)\n",
    "\n",
    "You will now implement the Viterbi algorithm. Complete the function `viterbi(sequence, p_start, p_trans, p_emiss, p_stop)` below.\n",
    "\n",
    "**Input:** sequence ($o_1, ..., o_N$), $P_\\text{start}$, $P_\\text{trans}$, $P_\\text{emiss}$, $P_\\text{stop}$\n",
    "\n",
    "*Forward pass: compute the best path for every end state*\n",
    "\n",
    "- set $\\text{viterbi}(1, c_k)$ for each $c_k$\n",
    "- for $i=2$ to $N$, and for each $c_k$, set $\\text{viterbi}(i, c_k$) and $\\text{backtrack}(i, c_k)$\n",
    "- $\\text{max_prob} = \\max_{c_l} P_{\\text{stop}}(\\text{stop} \\,|\\, c_l) \\times viterbi(N, c_l)$\n",
    "\n",
    "*Backward pass: backtrack to get most likely path*\n",
    "- $\\hat{s}_N = \\arg\\max_{c_l} P_\\text{stop}(\\text{stop} \\,|\\, c_l) \\times viterbi(N, c_l)$\n",
    "- for $i = N-1$ to $1$: $\\hat{s}_i = \\text{backtrack}(i+1, \\hat{s}_{i+1})$\n",
    "\n",
    "**Output:** max_prob, Viterbi path $\\hat{s}_1, \\hat{s}_2, \\dots, \\hat{s}_N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sequence, p_start=None, p_trans=None, p_stop=None, p_emiss=None):\n",
    "    \"\"\"\n",
    "    Compute the Viterbi sequence. \n",
    "    Note: you have to use log-probabilities!\n",
    "    \n",
    "    The return value should be a tuple (max_prob, list_of_viterbi_states)\n",
    "    Return:\n",
    "      - best_score (float) the log-probability of the best path\n",
    "      - best_path (int list) the best path as a list of state IDs\n",
    "    \"\"\"\n",
    "    \n",
    "    length = len(sequence)\n",
    "    num_states = len(p_start)\n",
    "    \n",
    "    # trellis to store Viterbi scores\n",
    "    # we store -inf as our initial scores since log(0)=-inf\n",
    "    trellis = np.full([length, num_states], -np.inf)\n",
    "\n",
    "    # backpointers to backtrack (to remember what prev. state caused the maximum score)\n",
    "    # we initialize with -1 values, to represent a non-existing index\n",
    "    backpointers = -np.ones([length, num_states], dtype=int)\n",
    "    # Initialise the first row of the trellis with the probabilities of the starting state + the log probability \n",
    "    # of outputting the correct observation\n",
    "    trellis[0,:] = p_start +  p_emiss[:, obs2i[sequence[0]]]\n",
    "    \n",
    "    #Loop through the observation sequence skipping the starting state since we initialised this earlier\n",
    "    for seq_i in range(1,length):\n",
    "        # loop through the states\n",
    "        for state_i in range(num_states):\n",
    "            # Initialise a holder variable with the sum of the previous probability states and the next states\n",
    "            t_prob = p_trans[:,state_i] + trellis[seq_i-1,:]  \n",
    "            # Initialise the next row of the column with the sum of the highest probability of going to a certain state and\n",
    "            # That state emisioning a certain observation\n",
    "            trellis[seq_i,state_i] = np.max(t_prob) + p_emiss[state_i,obs2i[sequence[seq_i]]]\n",
    "            # add the index of the highest probability to the backpointers\n",
    "            backpointers[seq_i-1,state_i] = np.argmax(t_prob)\n",
    "\n",
    "        \n",
    "    # Initialise the best path with a length of the observation sequence         \n",
    "    best_path = np.zeros(length, dtype=int)\n",
    "    # Since we know the last state we can insert it at the end of the best path\n",
    "    best_path[-1] = np.argmax(trellis[-1,:])\n",
    "    # holder variable for the highest probability\n",
    "    best_score = 0\n",
    "    # Loop through the observation sequence in a reversed fashion\n",
    "    for seq_i in reversed(range(length-1)):\n",
    "        # add the index of the highest probability corresponding to the observation to the best path\n",
    "        best_path[seq_i] = backpointers[seq_i,best_path[seq_i+1]]\n",
    "        # add the highest probability of the state/observation to the best score\n",
    "        best_score += trellis[seq_i,best_path[seq_i+1]]    \n",
    "    print(trellis)\n",
    "#     print()\n",
    "    return best_score, best_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out Viterbi\n",
    "\n",
    "Once you have implemented the Viterbi algorithm, try it out on the following sequence.\n",
    "\n",
    "Note: to get all points, make sure that the cell below runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.2341065   -1.18958407  -4.2341065 ]\n",
      " [ -5.89524579  -5.30098661  -3.33304747]\n",
      " [ -7.1712177   -6.29173847  -7.00691465]\n",
      " [-10.99740019  -8.2380978   -8.43520187]]\n",
      "Best score: -13.376568327474333\n",
      "Best path: [0 1 0 1]\n",
      "Test sequence ['sleep', 'cry', 'laugh', 'cry']\n",
      "Prediction ['happy', 'bored', 'happy', 'bored']\n",
      "[[-1.59108877 -0.7396672  -0.78015856]\n",
      " [-0.94446161 -3.78418963 -0.78015856]\n",
      " [-3.98898405 -1.38629436 -3.17805383]]\n",
      "[[-0.92576948 -3.76120012 -3.13549422]\n",
      " [-1.57239664 -0.32721291 -0.09097178]\n",
      " [-0.92576948 -1.36330484 -3.13549422]]\n",
      "[-1.09861229 -1.09861229 -1.09861229]\n",
      "{0: 'happy', 1: 'bored', 2: 'hungry'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test out your Viterbi-algorithm here.\"\"\"\n",
    "\n",
    "test_sequence = test_set[0]\n",
    "\n",
    "best_score, best_path = viterbi(test_sequence, p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
    "\n",
    "print('Best score:',best_score)\n",
    "print('Best path:',best_path)\n",
    "\n",
    "i2state = {v : k for k, v in state2i.items()}\n",
    "print('Test sequence',test_sequence)\n",
    "print('Prediction',[i2state[i] for i in best_path])\n",
    "print(p_trans)\n",
    "print(p_emiss)\n",
    "print(p_start)\n",
    "print(i2state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "-14.71644005\n",
      "Observation sequence:   O =  [2 1 0 1]\n",
      "Optimal state sequence: S =  [0 1 0 1]\n",
      "D_log =\n",
      "[[-2.02438177 -4.77398097 -4.96149297 -8.12497838]\n",
      " [-2.46191713 -3.29605629 -8.48054195 -6.23316749]\n",
      " [-4.23410651 -3.93918327 -7.81784487 -9.0414488 ]]\n",
      "exp(D_log) =\n",
      "[[1.32075471e-01 8.44668713e-03 7.00246555e-03 2.96051131e-04]\n",
      " [8.52713180e-02 3.70289111e-02 2.07466236e-04 1.96322355e-03]\n",
      " [1.44927535e-02 1.94641052e-02 4.02488163e-04 1.18399175e-04]]\n",
      "E =\n",
      "[[1 1 0]\n",
      " [0 2 0]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "def viterbi_log(A, C, B, O):\n",
    "    \"\"\"Viterbi algorithm (log variant) for solving the uncovering problem\n",
    "\n",
    "    Notebook: C5/C5S3_Viterbi.ipynb\n",
    "\n",
    "    Args:\n",
    "        A (np.ndarray): State transition probability matrix of dimension I x I\n",
    "        C (np.ndarray): Initial state distribution  of dimension I\n",
    "        B (np.ndarray): Output probability matrix of dimension I x K\n",
    "        O (np.ndarray): Observation sequence of length N\n",
    "\n",
    "    Returns:\n",
    "        S_opt (np.ndarray): Optimal state sequence of length N\n",
    "        D_log (np.ndarray): Accumulated log probability matrix\n",
    "        E (np.ndarray): Backtracking matrix\n",
    "    \"\"\"\n",
    "    I = A.shape[0]    # Number of states\n",
    "    N = len(O)  # Length of observation sequence\n",
    "#     tiny = np.finfo(0.).tiny\n",
    "    A_log = A\n",
    "    C_log = C\n",
    "    B_log = B\n",
    "\n",
    "    # Initialize D and E matrices\n",
    "    D_log = np.zeros((I, N))\n",
    "    E = np.zeros((I, N-1)).astype(np.int32)\n",
    "    D_log[:, 0] = C_log + B_log[:, O[0]]\n",
    "\n",
    "    # Compute D and E in a nested loop\n",
    "    for n in range(1, N):\n",
    "        for i in range(I):\n",
    "            temp_sum = A_log[:, i] + D_log[:, n-1]\n",
    "            D_log[i, n] = np.max(temp_sum) + B_log[i, O[n]]\n",
    "            E[i, n-1] = np.argmax(temp_sum)\n",
    "\n",
    "    # Backtracking\n",
    "    highest_score=np.argmax(D_log[:, -1])\n",
    "    S_opt = np.zeros(N).astype(np.int32)\n",
    "    S_opt[-1] = np.argmax(D_log[:, -1])\n",
    "    for n in range(N-2, -1, -1):\n",
    "        S_opt[n] = E[int(S_opt[n+1]), n]\n",
    "        highest_score += D_log[int(S_opt[n+1]), n]\n",
    "        print(S_opt[n])\n",
    "        \n",
    "    print(highest_score)\n",
    "\n",
    "    return S_opt, D_log, E\n",
    "\n",
    "# Apply Viterbi algorithm (log variant)\n",
    "\n",
    "\n",
    "A = np.array([[-1.59108877, -0.7396672,  -0.78015856],\n",
    "             [-0.94446161, -3.78418963, -0.78015856],\n",
    "             [-3.98898405, -1.38629436, -3.17805383]]).transpose()\n",
    "\n",
    "\n",
    "C = np.array([-1.09861229, -1.09861229, -1.09861229]).transpose()\n",
    "\n",
    "\n",
    "B = np.array([[-0.92576948, -3.76120012, -3.13549422],\n",
    "              [-1.57239664, -0.32721291, -0.09097178],\n",
    "              [-0.92576948, -1.36330484, -3.13549422]]).transpose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "O = np.array([2,1,0,1])\n",
    "\n",
    "\n",
    "S_opt, D_log, E = viterbi_log(A, C, B, O)\n",
    "\n",
    "print('Observation sequence:   O = ', O)\n",
    "print('Optimal state sequence: S = ', S_opt)\n",
    "# np.set_printoptions(formatter={'float': \"{: 7.2f}\".format})\n",
    "print('D_log =', D_log, sep='\\n')\n",
    "# np.set_printoptions(formatter={'float': \"{: 7.4f}\".format})\n",
    "print('exp(D_log) =', np.exp(D_log), sep='\\n')\n",
    "# np.set_printoptions(formatter={'float': \"{: 7.0f}\".format})\n",
    "print('E =', E, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2  0.4  0.  ]\n",
      " [0.5  0.   0.25]\n",
      " [0.5  0.5  0.  ]]\n",
      "[0.4  0.25 0.  ]\n",
      "Observation sequence:   O =  [2 1 0 1]\n",
      "Optimal state sequence: S =  [0 1 0 1]\n",
      "D =\n",
      "[[0.13333333 0.00833333 0.008      0.00032   ]\n",
      " [0.08333333 0.04       0.         0.0024    ]\n",
      " [0.         0.02083333 0.         0.        ]]\n",
      "E =\n",
      "[[1 1 0]\n",
      " [0 2 0]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "def viterbi(A, C, B, O):\n",
    "    \"\"\"Viterbi algorithm for solving the uncovering problem\n",
    "\n",
    "    Notebook: C5/C5S3_Viterbi.ipynb\n",
    "\n",
    "    Args:\n",
    "        A (np.ndarray): State transition probability matrix of dimension I x I\n",
    "        C (np.ndarray): Initial state distribution  of dimension I\n",
    "        B (np.ndarray): Output probability matrix of dimension I x K\n",
    "        O (np.ndarray): Observation sequence of length N\n",
    "\n",
    "    Returns:\n",
    "        S_opt (np.ndarray): Optimal state sequence of length N\n",
    "        D (np.ndarray): Accumulated probability matrix\n",
    "        E (np.ndarray): Backtracking matrix\n",
    "    \"\"\"\n",
    "    I = A.shape[0]    # Number of states\n",
    "    N = len(O)  # Length of observation sequence\n",
    "\n",
    "    # Initialize D and E matrices\n",
    "    D = np.zeros((I, N))\n",
    "    E = np.zeros((I, N-1)).astype(np.int32)\n",
    "    D[:, 0] = np.multiply(C, B[:, O[0]])\n",
    "\n",
    "    # Compute D and E in a nested loop\n",
    "    for n in range(1, N):\n",
    "        for i in range(I):\n",
    "            temp_product = np.multiply(A[:, i], D[:, n-1])\n",
    "            D[i, n] = np.max(temp_product) * B[i, O[n]]\n",
    "            E[i, n-1] = np.argmax(temp_product)\n",
    "\n",
    "    # Backtracking\n",
    "    S_opt = np.zeros(N).astype(np.int32)\n",
    "    S_opt[-1] = np.argmax(D[:, -1])\n",
    "    for n in range(N-2, -1, -1):\n",
    "        S_opt[n] = E[int(S_opt[n+1]), n]\n",
    "\n",
    "    return S_opt, D, E\n",
    "\n",
    "# Define model parameters\n",
    "# A = np.array([[0.8, 0.1, 0.1], \n",
    "#               [0.2, 0.7, 0.1], \n",
    "#               [0.1, 0.3, 0.6]])\n",
    "\n",
    "A = p_trans.transpose()\n",
    "print(A)\n",
    "B = p_emiss.transpose()\n",
    "print(p_stop_n)\n",
    "\n",
    "# A[0][2] = 0.4\n",
    "# A[1][1] = 0.25\n",
    "C = np.array(p_start)\n",
    "\n",
    "# B = np.array([[0.7, 0.0, 0.3], \n",
    "#               [0.1, 0.9, 0.0], \n",
    "#               [0.0, 0.2, 0.8]])\n",
    "\n",
    "\n",
    "O = np.array([2,1,0,1]).astype(np.int32)\n",
    "#O = np.array([1]).astype(np.int32)\n",
    "#O = np.array([1, 2, 0, 2, 2, 1]).astype(np.int32)\n",
    "\n",
    "# Apply Viterbi algorithm\n",
    "S_opt, D, E = viterbi(A, C, B, O)\n",
    "#\n",
    "print('Observation sequence:   O = ', O)\n",
    "print('Optimal state sequence: S = ', S_opt)\n",
    "# np.set_printoptions(formatter={'float': \"{: 7.4f}\".format})\n",
    "print('D =', D, sep='\\n')\n",
    "# np.set_printoptions(formatter={'float': \"{: 7.0f}\".format})\n",
    "print('E =', E, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.01706173,  1.09213729,  0.67188434, -2.49160107],\n",
       "       [ 1.49774345,  2.33732102, -3.61352444, -0.59979018],\n",
       "       [ 3.44469249,  0.17566688, -2.18446756, -3.40807149]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def viterbi4(y, A, B, Pi=None):\n",
    "    \"\"\"\n",
    "    Return the MAP estimate of state trajectory of Hidden Markov Model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array (T,)\n",
    "        Observation state sequence. int dtype.\n",
    "    A : array (K, K)\n",
    "        State transition matrix. See HiddenMarkovModel.state_transition  for\n",
    "        details.\n",
    "    B : array (K, M)\n",
    "        Emission matrix. See HiddenMarkovModel.emission for details.\n",
    "    Pi: optional, (K,)\n",
    "        Initial state probabilities: Pi[i] is the probability x[0] == i. If\n",
    "        None, uniform initial distribution is assumed (Pi[:] == 1/K).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : array (T,)\n",
    "        Maximum a posteriori probability estimate of hidden state trajectory,\n",
    "        conditioned on observation sequence y under the model parameters A, B,\n",
    "        Pi.\n",
    "    T1: array (K, T)\n",
    "        the probability of the most likely path so far\n",
    "    T2: array (K, T)\n",
    "        the x_j-1 of the most likely path so far\n",
    "    \"\"\"\n",
    "    # Cardinality of the state space\n",
    "    K = A.shape[0]\n",
    "    # Initialize the priors with default (uniform dist) if not given by caller\n",
    "    Pi = Pi if Pi is not None else np.full(K, 1 / K)\n",
    "    T = len(y)\n",
    "    T1 = np.empty((K, T), 'd')\n",
    "    T2 = np.empty((K, T), 'B')\n",
    "\n",
    "    # Initilaize the tracking tables from first observation\n",
    "    T1[:, 0] = Pi * B[:, y[0]]\n",
    "    T2[:, 0] = 0\n",
    "\n",
    "    # Iterate throught the observations updating the tracking tables\n",
    "    for i in range(1, T):\n",
    "        T1[:, i] = np.max(T1[:, i - 1] + A.T + B[np.newaxis, :, y[i]].T, 1)\n",
    "        T2[:, i] = np.argmax(T1[:, i - 1] + A.T, 1)\n",
    "\n",
    "    # Build the output, optimal model trajectory\n",
    "    x = np.empty(T, 'B')\n",
    "    x[-1] = np.argmax(T1[:, T - 1])\n",
    "    for i in reversed(range(1, T)):\n",
    "        x[i - 1] = T2[x[i], i]\n",
    "\n",
    "    return x, T1, T2\n",
    "\n",
    "\n",
    "# A = np.array([[-1.59108877, -0.7396672,  -0.78015856],\n",
    "#              [-0.94446161, -3.78418963, -0.78015856],\n",
    "#              [-3.98898405, -1.38629436, -3.17805383]])\n",
    "A = np.array([[-1.59108877,-0.94446161,-3.98898405],\n",
    "          [ -0.7396672,-3.78418963,-1.38629436],\n",
    "          [-0.78015856,-0.78015856,-3.17805383]])\n",
    "\n",
    "\n",
    "C = np.array([-1.09861229, -1.09861229, -1.09861229])\n",
    "\n",
    "\n",
    "# B = np.array([[-0.92576948, -3.76120012, -3.13549422],\n",
    "#               [-1.57239664, -0.32721291, -0.09097178],\n",
    "#               [-0.92576948, -1.36330484, -3.13549422]])\n",
    "\n",
    "B= np.array([[-0.92576948,-1.57239664,-0.92576948],\n",
    "             [-3.76120012,-0.32721291,-1.36330484],\n",
    "             [ -3.13549422,-0.09097178,-3.13549422]])\n",
    "\n",
    "O = np.array([2,1,0,1])\n",
    "\n",
    "x, T1, T2 = viterbi4(O,A,B,C)\n",
    "T1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6626d09623968520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have reached the end of lab 2.\n",
    "\n",
    "If you want an additional challenge,  go ahead and try the following sections. Otherwise, you're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4caecec1fc7924c9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Extra: Posterior Decoding\n",
    "\n",
    "What if we don't care about the global sequence of hidden states, but more about getting **individual** states right? \n",
    "We now aim to find the state with the **highest state posterior** for each position. So what is a state posterior? It is defined as:\n",
    "\n",
    "$$ P( s_i \\,|\\, o_1, o_2, \\dots, o_N) $$\n",
    "\n",
    "It gives the probability, with observation sequence $o_1, o_2, \\dots, o_N$, that the i'th hidden state was $s_i$. \n",
    "\n",
    "The best state $s_i^*$ for that position is then:\n",
    "\n",
    "$$ s_i^* = \\arg\\max_{s_i \\in \\Lambda} P( s_i \\,|\\, o_1, o_2, \\dots, o_N) $$\n",
    "\n",
    "If we calculate this for each position, we are performing posterior decoding. Do you see the difference with Viterbi? Now we choose the hidden states **independenly**, based on the observations $o = o_1, o_2, \\dots, o_N$, one position at a time. \n",
    "\n",
    "#### How to calculate a state posterior?\n",
    "\n",
    "Good question. Calculating the state posterior is not so easy. Remember that we are interested in one specific time step. To choose the best state for this time step, we need to take into account all paths that lead there. You will soon see why. \n",
    "\n",
    "First, let's define a few useful terms.\n",
    "\n",
    "**Sequence posterior**\n",
    "$$ P( s = s_1, s_2, \\dots, s_N \\,|\\, o = o_1, o_2, \\dots, o_N)  = \\frac{P(s, o)}{P(o)}$$\n",
    "\n",
    "To compute this, we need the **likelihood**:\n",
    "\n",
    "$$ P( o = o_1, o_2, \\dots, o_N ) = \\sum_{s} P(o, s)$$\n",
    "\n",
    "To calculate the likelihood, we thus need to sum over **all possible state sequences s**!\n",
    "\n",
    "Since the number of state sequences can grow so quickly, we will do something smarter than summing over all of them.\n",
    "(We used a similar trick with the Viterbi-algorithm!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a92a96f1a873e31",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Forward and Backward probabilities\n",
    "\n",
    "We can use compute **forward** and **backward** probabilities, which help us compute the likelihood in **linear time**: O(N).\n",
    "\n",
    "Let's first see how they are computed, before we will use them to calculate the likelihood (and finally the state posterior).\n",
    "\n",
    "The forward probability for a position i and a state $c_k$, gives us the probability of being in that state and that position, having observed $o_1, o_2, \\dots, o_i$:\n",
    "\n",
    "$$\\text{forward}(i, c_k) = P(c_k, o_1, o_2, \\dots, o_i)$$\n",
    "\n",
    "Because of the independence assumptions in the HMM, we can calculate the forward probability of position $i$ using the forward probabilities of each state in position $i-1$:\n",
    "\n",
    "$$\\text{forward}(i, c_k) = \\Big( \\sum_{c_l \\in \\Lambda} P_{\\text trans}(c_k \\,|\\, c_l) \\times \\text{forward}(i-1, c_l) \\Big) \\times P_{\\text emiss}(o_i \\,|\\, c_k)  $$\n",
    "\n",
    "And our special cases:\n",
    "\n",
    "$$\\text{forward}(1, c_k) =P_{\\text start}(c_k \\,|\\, \\text{start}) \\times P_{\\text emiss} (o_1 \\, |\\, c_k)$$\n",
    "$$\\text{forward}(N+1, \\text{stop}) = \\sum_{c_l \\in \\Lambda} P_{\\text trans}(\\text{stop} \\,|\\, c_l) \\times \\text{forward}(N, c_l) $$\n",
    "\n",
    "Did you notice that this is almost exactly the same as the Viterbi scores? Instead of taking the maximum, we are now **summing**!\n",
    "\n",
    "**Warning: you cannot \"just sum\" two probabilities in the log-domain!**\n",
    "A brute-force way to do this correctly would be to do $\\log(\\exp(a) + \\exp(b)$, i.e. convert the probabilities back and then sum, and then convert them to the log domain again. But this exposes us to numeric instabilities again! So a better way to do it is using $$\\log(\\exp(a) + \\exp(b)) = a + \\log(1 + \\exp(b − a)) \\qquad \\text{for } a < b$$\n",
    "\n",
    "We are providing a function `logsum()` for you that sums a list of values in the log-domain (using the above strategy).\n",
    "\n",
    "Now that we can compute forward probabilities: did you notice that $\\text{forward}(N+1, \\text{stop})$ gives us the **likelihood**, i.e. $P(o_1, o_2, \\dots, o_N)$? Take a moment to see why.\n",
    "\n",
    "Sadly, this is still not enough to calculate the state posteror. (You probably guessed, since this is calleed the Forward-**Backward** algorithm!). Right now we know the probability of being in state $s_i$ having observed $o_1, o_2, \\dots, o_i$, but we do **not** know the probability of being in that state knowing $o_{i+1}, \\dots, o_N$. This is what the backward probability gives us:\n",
    "\n",
    "$$\\text{backward}(i, c_l) = \\sum_{c_k \\in \\Lambda} P_\\text{trans}(c_k \\,|\\, c_l) \\times \\text{backward}(i+1,c_k) \\times P_\\text{emiss}(o_{i+1} \\,|\\, c_k)$$\n",
    "\n",
    "And our special cases:\n",
    "\n",
    "$$\\text{backward}(N, c_l) = P_\\text{stop}( \\text{stop} \\,|\\, c_l)$$\n",
    "$$\\text{backward}(0, \\text{start}) = \\sum_{c_k \\in \\Lambda} P_{\\text start}(c_k| \\text{start}) \\times \\text{backward}(1, c_k) \\times P_{\\text emiss}(o_1 \\,|\\, c_k)$$\n",
    "\n",
    "Can you see that we can also calculate the likelihood using just backward probabilities? You can find it in $\\text{backward}(0, \\text{start})$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f68826be76ed9405",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, implement the forward and backward algorithms.\n",
    "\n",
    "The forward function should return two values:\n",
    "\n",
    "- all forward scores for the trellis (length x num_states)\n",
    "- the forward score of the stop state (not part of the trellis)\n",
    "\n",
    "The backward function should similarly return two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsum(logv):\n",
    "    \"\"\"Sum of probabilities in log-domain.\"\"\"\n",
    "    res = -np.inf\n",
    "    for val in logv:\n",
    "        res = logsum_pair(res, val)\n",
    "    return res\n",
    "\n",
    "def logsum_pair(logx, logy):\n",
    "    \"\"\"\n",
    "    Return log(x+y), avoiding arithmetic underflow/overflow.\n",
    "    \"\"\"\n",
    "    if logx == -np.inf:\n",
    "        return logy\n",
    "    elif logx > logy:\n",
    "        return logx + np.log1p(np.exp(logy-logx))\n",
    "    else:\n",
    "        return logy + np.log1p(np.exp(logx-logy))\n",
    "\n",
    "\n",
    "def forward(sequence, p_start=None, p_trans=None, p_stop=None, p_emiss=None):\n",
    "    \"\"\"\n",
    "    Compute Forward probabilities.\n",
    "    Note: all probabilities should be log-probabilities.\n",
    "    \n",
    "    Return:\n",
    "      - trellis with forward probabilities, excluding the \"stop\" cell\n",
    "      - the forward probability of the stop cell (this is the log-likelihood!)\n",
    "    \"\"\"\n",
    "    \n",
    "    length = len(sequence)\n",
    "    num_states = len(p_start)\n",
    "    \n",
    "    # trellis to store forward probabilities\n",
    "    trellis = np.full([length, num_states], -np.inf)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return trellis, log_likelihood\n",
    "\n",
    "\n",
    "def backward(sequence, p_start=None, p_trans=None, p_stop=None, p_emiss=None):\n",
    "    \"\"\"\n",
    "    Compute Backward probabilities.\n",
    "    Note: all probabilities should be log-probabilities.\n",
    "    \n",
    "    Return:\n",
    "      - trellis with backward probabilities, excluding the \"start\" cell\n",
    "      - the forward probability of the start cell (this is ALSO the log-likelihood!)\n",
    "    \"\"\"\n",
    "    \n",
    "    length = len(sequence)\n",
    "    num_states = len(p_start)\n",
    "    \n",
    "    # trellis to store forward probabilities\n",
    "    trellis = np.full([length, num_states], -np.inf)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return trellis, log_likelihood\n",
    "\n",
    "\n",
    "def forward_backward(sequence):\n",
    "    \"\"\"\n",
    "    Compute forward and backward probabilities.\n",
    "    Return:\n",
    "    - fw_trellis\n",
    "    - fw_log_likelihood (the value of the \"stop\" cell, not part of the trellis)\n",
    "    - bw_trellis\n",
    "    - bw_log_likelihood (the value of the \"start\" cell, not part of the trellis)\n",
    "    \"\"\"\n",
    "    fw_trellis, fw_ll = forward(sequence, p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
    "    bw_trellis, bw_ll = backward(sequence, p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
    "    return fw_trellis, fw_ll, bw_trellis, bw_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-eb303f0eabac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfw_trellis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfw_ll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_trellis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_ll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-c1101e0c3277>\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(sequence)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;33m-\u001b[0m \u001b[0mbw_log_likelihood\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;34m\"start\"\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtrellis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mfw_trellis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfw_ll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_trans\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_trans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_emiss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_emiss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mbw_trellis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_ll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_trans\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_trans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_emiss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_emiss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfw_trellis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfw_ll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_trellis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_ll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-c1101e0c3277>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(sequence, p_start, p_trans, p_stop, p_emiss)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrellis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_sequence = test_set[0]\n",
    "\n",
    "fw_trellis, fw_ll, bw_trellis, bw_ll = forward_backward(test_sequence)\n",
    "\n",
    "print(test_sequence)\n",
    "print(fw_trellis)\n",
    "print(fw_ll)\n",
    "print(bw_trellis)\n",
    "print(bw_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Decoding\n",
    "\n",
    "Implement a function that, given the forward and backward probabilities, and a sequence of observations $o_1, o_2, \\dots, o_N$, returns the best hidden state sequence, according to posterior decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_decode(sequence, fw_trellis, bw_trellis, ll, p_trans, p_emiss):\n",
    "    \"\"\"\n",
    "    Return best hidden state sequence according to Posterior decoding\n",
    "    \"\"\"\n",
    "\n",
    "    length = len(sequence)\n",
    "    num_states = fw_trellis.shape[1]\n",
    "        \n",
    "    # calculate the state posteriors\n",
    "    state_posteriors = np.zeros([length, num_states])\n",
    "    \n",
    "    for i in range(length):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    state_posteriors = np.exp(state_posteriors)\n",
    "    \n",
    "    # the best states are simply the arg max of the state posteriors\n",
    "    best_sequence = np.argmax(state_posteriors, axis=1)\n",
    "\n",
    "    return state_posteriors, best_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_posteriors, best_sequence = posterior_decode(test_sequence, fw_trellis, bw_trellis, fw_ll, p_trans, p_emiss)\n",
    "\n",
    "print(state_posteriors)\n",
    "print(best_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              Acknowlegements: A version of this lab was originally developed in collaboration with J. Bastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
